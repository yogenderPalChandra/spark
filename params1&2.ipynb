{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "impressive-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "correct-remove",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "parental-clerk",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "micro-departure",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogender/.local/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "spark = sc.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "surprising-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_l = sc.wholeTextFiles(\"./*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "synthetic-today",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogender/.local/lib/python3.6/site-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "patient-mainland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Row('Masná, Praha 1 - Staré Město')>, <Row('Velvarská, Horoměřice')>, <Row('Libušina, Karlovy Vary')>, <Row('Pod Lipami, Praha 3 - Žižkov')>, <Row('Drnovská, Praha 6 - Ruzyně')>, <Row('V Průhoně, Mukařov - Žernovka')>, <Row('Mladoboleslavská, Mělník')>, <Row('Grafická, Praha 5 - Smíchov')>, <Row('Sametová, Liberec - Liberec VI-Rochlice')>, <Row('Jakubská, Praha 1 - Staré Město')>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(address='Masná, Praha 1 - Staré Město'),\n",
       " Row(address='Velvarská, Horoměřice'),\n",
       " Row(address='Libušina, Karlovy Vary'),\n",
       " Row(address='Pod Lipami, Praha 3 - Žižkov'),\n",
       " Row(address='Drnovská, Praha 6 - Ruzyně'),\n",
       " Row(address='V Průhoně, Mukařov - Žernovka'),\n",
       " Row(address='Mladoboleslavská, Mělník'),\n",
       " Row(address='Grafická, Praha 5 - Smíchov'),\n",
       " Row(address='Sametová, Liberec - Liberec VI-Rochlice'),\n",
       " Row(address='Jakubská, Praha 1 - Staré Město')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = rdd_l.map(lambda x: x[1]).map(lambda x: x.split('\\n\\t')).map(lambda x: x[6]) \\\n",
    ".map(lambda x: x.split('prodeji')).map(lambda x: x[1]).map(lambda x: x.split(';')) \\\n",
    ".map(lambda x: x[0]).map(lambda x: x.strip(' '))\n",
    "\n",
    "rows_split_addr = rdd1.map(lambda p: Row(p))\n",
    "\n",
    "print(rows_split_addr.collect())\n",
    "\n",
    "schemaString = \"address\"\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "addressSchema = sqlContext.createDataFrame(rows_split_addr, schema)\n",
    "#print(addressSchema.collect())\n",
    "addressSchema.repartition(1).write.csv(path='./data.csv', mode=\"append\", header=\"true\")\n",
    "addressSchema.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "responsible-commodity",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[ 10.2, \"Fred\",123]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "representative-gnome",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"sales\", FloatType(),True),    \n",
    "    StructField(\"employee\", StringType(),True),\n",
    "    StructField(\"ID\", IntegerType(),True)\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "occupational-basics",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "createDataFrame() missing 1 required positional argument: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-57ddcfa0cb3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: createDataFrame() missing 1 required positional argument: 'data'"
     ]
    }
   ],
   "source": [
    "df = SQLContext.createDataFrame(data, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "unique-shape",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparkContext' object has no attribute 'udf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-b37e79d0be54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mSimplifiedDoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"text_simple_udf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_simple_udf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#test the udf with a sample from the dataframe:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparkContext' object has no attribute 'udf'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from simplified_scrapy.simplified_doc import SimplifiedDoc \n",
    "\n",
    "#define and register udf\n",
    "\n",
    "def text_simple_udf(text_in): \n",
    "    return SimplifiedDoc(text_in).text\n",
    "\n",
    "spark.udf.register(\"text_simple_udf\", text_simple_udf)\n",
    "\n",
    "#test the udf with a sample from the dataframe:\n",
    "\n",
    "tst = text_simple_udf('<p>Tervetuloa leikkimään, laulamaan, loruilemaan, liikkumaan, taiteilemaan ja tutkimaan leikkipuiston<br>perheaamuun! Leikki- ja toimintaympäristö mahdollistavat vanhemman ja lapsen yhteisen puuhan ja leikin<br>ja lapset saavat leikkiseuraa.<br>Vanhemmilla on mahdollisuus tutustua muihin lapsiperheisiin ja lapset saavat leikkiseuraa. Vanhemmat ja<br>lapset voivat osallistua toiminnan suunnittel')\n",
    "print(tst)\n",
    "\n",
    "# apply in dataframe:\n",
    "#dfAll4.selectExpr(\"desc\", \"(text_simple_udf(desc)) as desc_simpl\").show(10, truncate=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-fight",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
