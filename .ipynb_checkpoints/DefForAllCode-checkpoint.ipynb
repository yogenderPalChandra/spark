{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "caroline-leadership",
   "metadata": {},
   "source": [
    "### \"If after painstaking efforts you made the code work on Spark clusters, remember that Spark clusters are just a bunch of rocks you tricked into thinking - Unknown!\"\n",
    "\n",
    "#### !!!! Status of Task: Completed All Three tasks (last task still need some cleaning - I ran out of time, unfortunately but 90% of the third task - parsing etc is all done )!!!\n",
    "\n",
    "#### I will demonstrate three methods to tackle with such kind of problems\n",
    "##### Method1: Spark-nlp by John Snow Labs\n",
    "Why Spark-nlp for this solution?\n",
    "\n",
    "Since we are dealing with text data (on spark) and I am coming from the Deep learning part too it's not any harm to assume the end consumer of the scrapped data could be some Natural Language Processing (NLP) pipeline. NLP actually tokenisess, vectorizes and does compute/memory intensive mathematical operations such as word2vec on textual data under the hood. So that is the reason why I choose spark-nlp to demonstrate the first part of the Task.¶\n",
    "\n",
    "#### Method 2: Regular Transformations, Actions Operations on RDDs\n",
    "I tried to solve Second part of Task using regular RDD Operations, they are self explined and I have added comments\n",
    "\n",
    "##### Method 3: Using custom Beautiful Soup user defined functions (UDF) in Spark. [The most versitle and easy]\n",
    "The whole task can be done using this UDF method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subjective-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#prepare environment:\n",
    "#One can use conda environment:\n",
    "#cd /path/to/directory/where/files/are/located\n",
    "#conda create -n pyspark_env\n",
    "#conda activate pyspark_env\n",
    "#conda install -c conda-forge pyspark\n",
    "\n",
    "#Export path to where pyspark is installed:\n",
    "#export SPARK_HOME=/path/to/pyspark #Check correct path! its important otherwise spark will not run\n",
    "#optional if you want to launch from other terminals too\n",
    "#source ~/.bashrc\n",
    "\n",
    "#try if spark runs:\n",
    "#spark-shell #works\n",
    "\n",
    "#Install spark-nlp #https://nlp.johnsnowlabs.com/docs/en/install\n",
    "#conda install -c johnsnowlabs spark-nlp\n",
    "\n",
    "#Export python path for both driver and worker nodes:\n",
    "#python version shuld be same for both\n",
    "#thats why it is important to work in conda/Python virtual environment,so as to not to clash the python versions\n",
    "# in both nodes.\n",
    "#export PYSPARK_PYTHON=\"path/to/python\" # path shoudl be something like cwd/conda/env/bin/...\n",
    "#export PYSPARK_DRIVER_PYTHON=\"path/to/python\"\n",
    "\n",
    "#install Beautiful Soup too\n",
    "#conda install -c anaconda beautifulsoup4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "chinese-prize",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogender/.local/lib/python3.6/site-packages/pyspark/context.py:238: FutureWarning: Python 3.6 support is deprecated in Spark 3.2.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "#Import what is needed\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import SQLContext, Row\n",
    "from sparknlp.base import *\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "import sparknlp\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "#from py4j.java_gateway import java_import\n",
    "import sparknlp\n",
    "sc = sparknlp.start()\n",
    "#sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "descending-wagon",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yogender/.local/lib/python3.6/site-packages/pyspark/sql/context.py:79: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "certified-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./*html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arctic-deadline",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_l(path):\n",
    "    \"\"\"path to rdd builder\n",
    "    \n",
    "    takes path as argument and returns rdd \n",
    "    \"\"\"\n",
    "\n",
    "    return sc.sparkContext.wholeTextFiles(\"./*.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "introductory-bikini",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df(rdd_l):\n",
    "    \"\"\" rdd to df builder\n",
    "    \n",
    "    takes list of rdd (rdd_l) as argument and returns rdd dataframe (df).\n",
    "    \n",
    "    rdd stores values as a tuple of filnename and the actual value (HTML doc) in this case\n",
    "    \"\"\"\n",
    "    return rdd_l.toDF(schema=[\"filename\", \"text\"]).select(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "brown-budapest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "insured-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def file_for_regex_transformer():\n",
    "    \n",
    "    \"\"\"Regex rules to file in current directory\n",
    "    \n",
    "    This function returns path to file with rules string for Regex matcher pipline\n",
    "    \n",
    "    in the function nlp_pipline_and_clean(rdd_df)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    rules = '''.\\d\\&\\w+\\;\\d+&\\w+;\\d+&\\w+;Kč*'''\n",
    "    with open('regex_rules.txt', 'w') as f:\n",
    "        f.write(rules)\n",
    "    return os.path.join(os.getcwd(), \"regex_rules.txt\")\n",
    "\n",
    "#file_2_regex_transformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "spatial-enclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RegexMatcher_882bfc736ab1', name='lazyAnnotator', doc='Whether this AnnotatorModel acts as lazy in RecursivePipelines'): False,\n",
       " Param(parent='RegexMatcher_882bfc736ab1', name='strategy', doc='MATCH_FIRST|MATCH_ALL|MATCH_COMPLETE'): 'MATCH_ALL'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RegexMatcher().extractParamMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "magnetic-plane",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nlp_pipline_and_clean(rdd_df):\n",
    "    \n",
    "    \"\"\"takes rdd dataframe rdd_df and returns regex matches item i.e. class=\"norm-price ng-binding\n",
    "    \n",
    "    :DocumentAssembler():  is a sparknlp.base class Transformer \n",
    "    which takes rdd with input column (setInputCol()) ->test and returns rdd with column 'assembled'\n",
    "    :RegexMatcher(): is a the Spark NLP transformer which actually does regex matching \n",
    "    of the string we defined in the previous function.  It takes 'assembled' column as input and returns\n",
    "    'regex_matches' column \n",
    "    :nlpPipeline: a pipline is initialised and called on the rdd_df\n",
    "    \"\"\"\n",
    "    \n",
    "    documentAssembler = DocumentAssembler()\\\n",
    "        .setInputCol(\"text\")\\\n",
    "        .setOutputCol(\"assembled\")\n",
    "\n",
    "    regex_matcher = RegexMatcher()\\\n",
    "        .setInputCols('assembled')\\\n",
    "        .setStrategy(\"MATCH_ALL\")\\\n",
    "        .setOutputCol(\"regex_matches\")\\\n",
    "        .setExternalRules(path=file_for_regex_transformer(), delimiter=',')\n",
    "\n",
    "    nlpPipeline = Pipeline(stages=[\n",
    "        documentAssembler, \n",
    "        regex_matcher\n",
    "     ])\n",
    "    \n",
    "    return nlpPipeline.fit(rdd_df).transform(rdd_df) \\\n",
    ".select(\"regex_matches.result\") \\\n",
    ".rdd.flatMap(lambda x: x[0])\\\n",
    ".map(lambda s: s.replace('&nbsp;', '')) \\\n",
    ".map(lambda s: s.replace('>', '')) \\\n",
    ".map(lambda s: s.replace('>', '')) \\\n",
    ".map(lambda s: s.replace('Kč', ' Kč')) \\\n",
    ".map(lambda s: s.split()) \\\n",
    ".map(lambda s: '{:,} {}'.format(int(s[0]), str(s[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabulous-procurement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nlp_pipline_and_clean(df(rdd_l(path))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accredited-helena",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_df_2_pd_df(rdd_df):\n",
    "    \"\"\" changes the name of rdd rows to more identifiable name - cost\n",
    "    returns pandas df\n",
    "    \"\"\"\n",
    "    row = Row(\"cost\") \n",
    "    match_df_flat1_df= rdd_df.map(row).toDF()\n",
    "    return  match_df_flat1_df.toPandas()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "postal-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rdd_df_2_pd_df(nlp_pipline_and_clean(df(rdd_l(path))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unusual-prince",
   "metadata": {},
   "source": [
    "### Part2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "electrical-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rdd_2_address(rdd_df):\n",
    "    \n",
    "    '''Takes rdd dataframe cleans it and returns pandas df \n",
    "    \n",
    "    :rdd_l.map(lambda x: x[1]): takes the data out of tuple of rdd. because rdd when read using WholeTextFile stores\n",
    "    tuple(fileNamle, StringData).\n",
    "    :.map(lambda x: x.split('\\n\\t')): split the data by combination of next line and tab seperater.\n",
    "    :.map(lambda x: x[6]): Pick up the 6th row from rdds as it is the intended class=\"location-text ng-binding\"\n",
    "    :.map(lambda x: x.split('prodeji')): split by prodej to get meaningfull string\n",
    "    :.map(lambda x: x[1]): some indexing to pick elemnt out of list of list\n",
    "    :.map(lambda x: x.split(';')): split it at ; because thats where address seperates \n",
    "    :.map(lambda x: x[0]): again pick element from lol (list of list) or tuple\n",
    "    :.map(lambda x: x.strip(' ')): strip out empty space\n",
    "    '''\n",
    "    \n",
    "    rdd1 = rdd_df.map(lambda x: x[1]).map(lambda x: x.split('\\n\\t')).map(lambda x: x[6]) \\\n",
    "    .map(lambda x: x.split('prodeji')).map(lambda x: x[1]).map(lambda x: x.split(';')) \\\n",
    "    .map(lambda x: x[0]).map(lambda x: x.strip(' ')).map(lambda x: str(x)).map(lambda p: Row(p))\n",
    "\n",
    "    schemaString = \"address\"\n",
    "    fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "    schema = StructType(fields)\n",
    "    addressSchema = sqlContext.createDataFrame(rdd1, schema)\n",
    "    return addressSchema.toPandas()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revolutionary-contents",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ecological-terminology",
   "metadata": {},
   "source": [
    "### Part3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "generic-bubble",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_fileName_rdd(rdd_l, columnName=None):\n",
    "    \n",
    "    \"\"\"Takes rdd_l and change the name according to what we provide\n",
    "    Also, indexes out the data.\n",
    "    \"\"\"\n",
    "    \n",
    "    from pyspark.sql import Row\n",
    "    columnName = str(columnName)\n",
    "    row = Row(columnName) # Or some other column name\n",
    "    return rdd_l.map(lambda x: x[1]).map(row).toDF()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "diagnostic-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove_fileName_rdd(rdd_l(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "amended-activity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def processRecord_udf_param1(rdd_l):\n",
    "    \"\"\" Beautiful Soup UDF takes rdd_l parses  needed HTML <tag>:class=\"params1\"\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(rdd_l, \"html.parser\")\n",
    "    classes = []\n",
    "    for element in soup.find_all('ul', class_='params1'):\n",
    "        for il in element.find_all('li'):\n",
    "            text = il.get_text(strip=True).replace(u'\\xa0', u' ')\n",
    "            classes.append(text)\n",
    "\n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "political-growing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_apply_udf(rdd_l):\n",
    "    \"\"\" this function applies the UDF UDF to the rdd_l\n",
    "    \"\"\"\n",
    "    apply2lambdafunc = lambda z: processRecord_udf_param1(z)\n",
    "\n",
    "    return remove_fileName_rdd(rdd_l(path), columnName='val'). \\\n",
    "withColumn('cleaned', udf(apply2lambdafunc, StringType())('val')) \\\n",
    ".select(\"cleaned\").rdd.flatMap(lambda x: x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "atomic-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#register_apply_udf(rdd_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "joined-perception",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned2pd_param1(cleaned_rdd_l):\n",
    "    \"\"\"convert the parsed information i.e. parama1 to rdd df and then to Pandas df\n",
    "    \"\"\"\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    row = Row(\"cleanedParams1\") \n",
    "    return cleaned_rdd_l.map(row).toDF().select('cleanedParams1').toPandas()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "generic-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned2pd_param1(register_apply_udf(rdd_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-period",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extensive-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def processRecord_udf_param2(file):\n",
    "    \"\"\" Same function but for Param2 parsing \n",
    "    using Beautiful Soup UDF takes class='params2' <tag>\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "\n",
    "    classes = []\n",
    "    for element in soup.find_all('ul', class_='params2'):\n",
    "        for il in element.find_all('li'):\n",
    "            text = il.get_text(strip=True).replace(u'\\xa0', u' ')\n",
    "\n",
    "            classes.append(text)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "broken-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef processRecord(file):\\n\\n    soup = BeautifulSoup(file, \"html.parser\")\\n    \\n    classes1 = []\\n    classes2 = []\\n\\n    for element1, element2 in zip(coup.find_all(\\'ul\\', class_=\\'params1\\'),coup.find_all(\\'ul\\', class_=\\'params2\\') ):\\n        for il1, il2 in zip(element1.find_all(\\'li\\'), element2.find_all(\\'li\\') ):\\n            text1 = il1.get_text(strip=True).replace(u\\'\\xa0\\', u\\' \\')\\n            text2 = il2.get_text(strip=True).replace(u\\'\\xa0\\', u\\' \\')\\n            classes1.append(text1)\\n            classes2.append(text2)\\n    return [classes1, classes2]\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#but Why not automate both param1 and param2 functions? \n",
    "#one can here is the code using zip looping concurrently over both the <html tags>\n",
    "#I just choose to make things more simple and human readable.\n",
    "\n",
    "'''\n",
    "def processRecord(file):\n",
    "\n",
    "    soup = BeautifulSoup(file, \"html.parser\")\n",
    "    \n",
    "    classes1 = []\n",
    "    classes2 = []\n",
    "\n",
    "    for element1, element2 in zip(coup.find_all('ul', class_='params1'),coup.find_all('ul', class_='params2') ):\n",
    "        for il1, il2 in zip(element1.find_all('li'), element2.find_all('li') ):\n",
    "            text1 = il1.get_text(strip=True).replace(u'\\xa0', u' ')\n",
    "            text2 = il2.get_text(strip=True).replace(u'\\xa0', u' ')\n",
    "            classes1.append(text1)\n",
    "            classes2.append(text2)\n",
    "    return [classes1, classes2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bronze-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_apply_udf_param2(rdd_l):\n",
    "    \"\"\"same apply UDF to rdd_l\n",
    "    \"\"\"\n",
    "    apply2lambdafunc = lambda z: processRecord_udf_param2(z)\n",
    "    \n",
    "    return remove_fileName_rdd(rdd_l(path), columnName='val'). \\\n",
    "withColumn('cleaned', udf(apply2lambdafunc, StringType())('val')) \\\n",
    ".select(\"cleaned\").rdd.flatMap(lambda x: x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "independent-coupon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaned2pd_param2(cleaned_rdd_l):\n",
    "    \"\"\"cleaned tags to df to pandas df\n",
    "    \"\"\"\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    row = Row(\"cleanedParams2\") \n",
    "    return cleaned_rdd_l.map(row).toDF().select('cleanedParams2').toPandas()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adjustable-arthritis",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned2pd_param2(register_apply_udf_param2(rdd_l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "waiting-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pd_2_csv(df1, df2, df3, df4):\n",
    "    \"\"\"concat all pandas dfs. \n",
    "    One can choose to join rdd dfs itself but I find pandas more easy to work with.\n",
    "    Pandas work with driver node only, so it is a layer which reduces data on driver.\n",
    "    from this step ownwards, computing is mo more distributed. To solve this issue one can even use\n",
    "    pandas pyspark.pandas library: https://spark.apache.org/\n",
    "    \"\"\"\n",
    "    df_concat = pd.concat ([df1, df2, df3, df4], axis=1)\n",
    "    df_concat.to_csv(\"cleaned_data.csv\", sep=',')\n",
    "    return df_concat\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "authorized-character",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cost</th>\n",
       "      <th>address</th>\n",
       "      <th>cleanedParams1</th>\n",
       "      <th>cleanedParams2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21,500,000 Kč</td>\n",
       "      <td>Masná, Praha 1 - Staré Město</td>\n",
       "      <td>[Celková cena:21 500 000 Kč za nemovitost, včetně provize, ID zakázky:32863, Aktualizace:16.02.2021, Stavba:Cihlová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní]</td>\n",
       "      <td>[Podlaží:2. podlaží, Užitná plocha:136m2, Plocha podlahová:136m2, Topení:Lokální plynové, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 78/2013 Sb. podle vyhlášky]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5,200,000 Kč</td>\n",
       "      <td>Velvarská, Horoměřice</td>\n",
       "      <td>[Celková cena:5 200 000 Kč za nemovitost, včetně provize, ID zakázky:729030, Aktualizace:08.02.2021, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:2. podlaží z celkem 3, Užitná plocha:78m2, Plocha podlahová:78m2]</td>\n",
       "      <td>[Parkování:1, Voda:Dálkový vodovod, Topení:Lokální plynové, Odpad:Veřejná kanalizace, Telekomunikace:Internet, Elektřina:230V, Doprava:MHD, Autobus, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 148/2007 Sb. podle vyhlášky, Vybavení:Částečně, Výtah:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10,854,900 Kč</td>\n",
       "      <td>Libušina, Karlovy Vary</td>\n",
       "      <td>[Celková cena:10 854 900 Kč (420 000 EUR) za nemovitost, včetně provize, Aktualizace:26.01.2021, ID:261724, Stavba:Smíšená, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Podlaží:2. podlaží, Užitná plocha:132m2, Balkón:, Parkování:]</td>\n",
       "      <td>[Voda:Dálkový vodovod, Odpad:Veřejná kanalizace, Doprava:Silnice, MHD, Autobus, Komunikace:Asfaltová, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná, Bezbariérový:, Vybavení:, Výtah:, Typ bytu:Mezonet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5,565,000 Kč</td>\n",
       "      <td>Pod Lipami, Praha 3 - Žižkov</td>\n",
       "      <td>[Celková cena:5 565 000 Kč za nemovitost, včetně provize, Poznámka k ceně:+ poplatky 3.500 ,- Kč, ID zakázky:N03409, Aktualizace:18.02.2021, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:4. podlaží z celkem 6, Užitná plocha:55m2, Plocha podlahová:55m2]</td>\n",
       "      <td>[Balkón:2m2, Sklep:2m2, Topení:Ústřední dálkové, Plyn:Plynovod, Telekomunikace:Telefon, Internet, Kabelová televize, Elektřina:230V, Doprava:Silnice, MHD, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1,475,000 Kč</td>\n",
       "      <td>Drnovská, Praha 6 - Ruzyně</td>\n",
       "      <td>[Celková cena:1 475 000 Kč za nemovitost, včetně provize, Poznámka k ceně:včetně právního servisu a provize RK, ID zakázky:0253-NP01146, Aktualizace:11.02.2021, Anuita:4 Kč, Stavba:Cihlová, Stav objektu:Novostavba, Vlastnictví:Družstevní, Převod do OV:Ne, Umístění objektu:Centrum obce, Podlaží:4. podlaží z celkem 6, Užitná plocha:57m2, Plocha podlahová:57m2]</td>\n",
       "      <td>[Balkón:4m2, Sklep:, Garáž:1, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Kabelová televize, Elektřina:230V, Doprava:MHD, Komunikace:Asfaltová, Energetická náročnost budovy:Třída B - Velmi úsporná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5,500,000 Kč</td>\n",
       "      <td>V Průhoně, Mukařov - Žernovka</td>\n",
       "      <td>[Celková cena:5 500 000 Kč za nemovitost, Poznámka k ceně:cena je včetně provize a služeb RK, ID zakázky:NPDO4772, Aktualizace:15.02.2021, Stavba:Cihlová, Stav objektu:Novostavba, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:1. podlaží z celkem 2, Užitná plocha:66m2]</td>\n",
       "      <td>[Plocha podlahová:66m2, Parkování:2, Rok kolaudace:2020, Voda:Dálkový vodovod, Odpad:Jímka, Telekomunikace:Internet, Doprava:Silnice, Autobus, Komunikace:Dlážděná, Energetická náročnost budovy:Třída B - Velmi úsporná]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2,530,000 Kč</td>\n",
       "      <td>Mladoboleslavská, Mělník</td>\n",
       "      <td>[Celková cena:2 530 000 Kč za nemovitost, + provize RK, včetně právního servisu (k jednání), Poznámka k ceně:, 3500, ID zakázky:1579/1830, Aktualizace:15.02.2021, Stavba:Panelová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní, Podlaží:1. podlaží z celkem 5, Užitná plocha:44m2, Plocha podlahová:44m2]</td>\n",
       "      <td>[Sklep:2m2, Voda:Dálkový vodovod, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Kabelové rozvody, Elektřina:230V, 400V, Doprava:Vlak, Silnice, MHD, Autobus, Komunikace:Asfaltová, Bezbariérový:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7,511,000 Kč</td>\n",
       "      <td>Grafická, Praha 5 - Smíchov</td>\n",
       "      <td>[Celková cena:7 511 000 Kč za nemovitost, + provize RK, včetně právního servisu, Poznámka k ceně:+ provize RK, ID zakázky:202009Graf, Aktualizace:14.02.2021, Stavba:Cihlová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní, Umístění objektu:Centrum obce, Podlaží:4. podlaží z celkem 5 včetně 1 podzemního, Užitná plocha:58m2, Datum nastěhování:Ihned, Rok kolaudace:2021]</td>\n",
       "      <td>[Rok rekonstrukce:2020, Voda:Dálkový vodovod, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Telefon, Internet, Elektřina:230V, Doprava:Vlak, Dálnice, Silnice, MHD, Autobus, Komunikace:Asfaltová, Energetická náročnost budovy:Třída A - Mimořádně úsporná č. 78/2013 Sb. podle vyhlášky, Bezbariérový:, Výtah:, Typ bytu:Mezonet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1,850,000 Kč</td>\n",
       "      <td>Sametová, Liberec - Liberec VI-Rochlice</td>\n",
       "      <td>[Celková cena:1 850 000 Kč za nemovitost, Náklady na bydlení:3000,-Kč, Aktualizace:04.02.2021, ID:695644, Stavba:Panelová, Stav objektu:Před rekonstrukcí, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:10. podlaží, Užitná plocha:33m2]</td>\n",
       "      <td>[Sklep:3m2, Voda:Dálkový vodovod, Topení:Jiné, Odpad:Veřejná kanalizace, Telekomunikace:Telefon, Internet, Kabelová televize, Elektřina:230V, Doprava:MHD, Komunikace:Asfaltová, Výtah:]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7,490,000 Kč</td>\n",
       "      <td>Jakubská, Praha 1 - Staré Město</td>\n",
       "      <td>[Celková cena:7 490 000 Kč za nemovitost, včetně provize, ID zakázky:N05057, Aktualizace:26.10.2020, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Podlaží:3. podlaží z celkem 4 včetně 1 podzemního, Užitná plocha:39m2]</td>\n",
       "      <td>[Plocha podlahová:39m2, Sklep:, Datum nastěhování:Ihned, Voda:Dálkový vodovod, Plyn:Plynovod, Energetická náročnost budovy:Třída D - Méně úsporná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            cost                                  address  \\\n",
       "0  21,500,000 Kč             Masná, Praha 1 - Staré Město   \n",
       "1   5,200,000 Kč                    Velvarská, Horoměřice   \n",
       "2  10,854,900 Kč                   Libušina, Karlovy Vary   \n",
       "3   5,565,000 Kč             Pod Lipami, Praha 3 - Žižkov   \n",
       "4   1,475,000 Kč               Drnovská, Praha 6 - Ruzyně   \n",
       "5   5,500,000 Kč            V Průhoně, Mukařov - Žernovka   \n",
       "6   2,530,000 Kč                 Mladoboleslavská, Mělník   \n",
       "7   7,511,000 Kč              Grafická, Praha 5 - Smíchov   \n",
       "8   1,850,000 Kč  Sametová, Liberec - Liberec VI-Rochlice   \n",
       "9   7,490,000 Kč          Jakubská, Praha 1 - Staré Město   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                       cleanedParams1  \\\n",
       "0                                                                                                                                                                                                              [Celková cena:21 500 000 Kč za nemovitost, včetně provize, ID zakázky:32863, Aktualizace:16.02.2021, Stavba:Cihlová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní]   \n",
       "1                                                                                                     [Celková cena:5 200 000 Kč za nemovitost, včetně provize, ID zakázky:729030, Aktualizace:08.02.2021, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:2. podlaží z celkem 3, Užitná plocha:78m2, Plocha podlahová:78m2]   \n",
       "2                                                                                                                                             [Celková cena:10 854 900 Kč (420 000 EUR) za nemovitost, včetně provize, Aktualizace:26.01.2021, ID:261724, Stavba:Smíšená, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Podlaží:2. podlaží, Užitná plocha:132m2, Balkón:, Parkování:]   \n",
       "3                                                             [Celková cena:5 565 000 Kč za nemovitost, včetně provize, Poznámka k ceně:+ poplatky 3.500 ,- Kč, ID zakázky:N03409, Aktualizace:18.02.2021, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:4. podlaží z celkem 6, Užitná plocha:55m2, Plocha podlahová:55m2]   \n",
       "4            [Celková cena:1 475 000 Kč za nemovitost, včetně provize, Poznámka k ceně:včetně právního servisu a provize RK, ID zakázky:0253-NP01146, Aktualizace:11.02.2021, Anuita:4 Kč, Stavba:Cihlová, Stav objektu:Novostavba, Vlastnictví:Družstevní, Převod do OV:Ne, Umístění objektu:Centrum obce, Podlaží:4. podlaží z celkem 6, Užitná plocha:57m2, Plocha podlahová:57m2]   \n",
       "5                                                                                       [Celková cena:5 500 000 Kč za nemovitost, Poznámka k ceně:cena je včetně provize a služeb RK, ID zakázky:NPDO4772, Aktualizace:15.02.2021, Stavba:Cihlová, Stav objektu:Novostavba, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:1. podlaží z celkem 2, Užitná plocha:66m2]   \n",
       "6                                                                     [Celková cena:2 530 000 Kč za nemovitost, + provize RK, včetně právního servisu (k jednání), Poznámka k ceně:, 3500, ID zakázky:1579/1830, Aktualizace:15.02.2021, Stavba:Panelová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní, Podlaží:1. podlaží z celkem 5, Užitná plocha:44m2, Plocha podlahová:44m2]   \n",
       "7  [Celková cena:7 511 000 Kč za nemovitost, + provize RK, včetně právního servisu, Poznámka k ceně:+ provize RK, ID zakázky:202009Graf, Aktualizace:14.02.2021, Stavba:Cihlová, Stav objektu:Po rekonstrukci, Vlastnictví:Osobní, Umístění objektu:Centrum obce, Podlaží:4. podlaží z celkem 5 včetně 1 podzemního, Užitná plocha:58m2, Datum nastěhování:Ihned, Rok kolaudace:2021]   \n",
       "8                                                                                                                          [Celková cena:1 850 000 Kč za nemovitost, Náklady na bydlení:3000,-Kč, Aktualizace:04.02.2021, ID:695644, Stavba:Panelová, Stav objektu:Před rekonstrukcí, Vlastnictví:Osobní, Umístění objektu:Klidná část obce, Podlaží:10. podlaží, Užitná plocha:33m2]   \n",
       "9                                                                                                                                           [Celková cena:7 490 000 Kč za nemovitost, včetně provize, ID zakázky:N05057, Aktualizace:26.10.2020, Stavba:Cihlová, Stav objektu:Velmi dobrý, Vlastnictví:Osobní, Podlaží:3. podlaží z celkem 4 včetně 1 podzemního, Užitná plocha:39m2]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                            cleanedParams2  \n",
       "0                                                                                                                                                                   [Podlaží:2. podlaží, Užitná plocha:136m2, Plocha podlahová:136m2, Topení:Lokální plynové, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 78/2013 Sb. podle vyhlášky]  \n",
       "1                                                                            [Parkování:1, Voda:Dálkový vodovod, Topení:Lokální plynové, Odpad:Veřejná kanalizace, Telekomunikace:Internet, Elektřina:230V, Doprava:MHD, Autobus, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 148/2007 Sb. podle vyhlášky, Vybavení:Částečně, Výtah:]  \n",
       "2                                                                                                                                 [Voda:Dálkový vodovod, Odpad:Veřejná kanalizace, Doprava:Silnice, MHD, Autobus, Komunikace:Asfaltová, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná, Bezbariérový:, Vybavení:, Výtah:, Typ bytu:Mezonet]  \n",
       "3                                                                               [Balkón:2m2, Sklep:2m2, Topení:Ústřední dálkové, Plyn:Plynovod, Telekomunikace:Telefon, Internet, Kabelová televize, Elektřina:230V, Doprava:Silnice, MHD, Energetická náročnost budovy:Třída G - Mimořádně nehospodárná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]  \n",
       "4                                                                             [Balkón:4m2, Sklep:, Garáž:1, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Kabelová televize, Elektřina:230V, Doprava:MHD, Komunikace:Asfaltová, Energetická náročnost budovy:Třída B - Velmi úsporná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]  \n",
       "5                                                                                                                                [Plocha podlahová:66m2, Parkování:2, Rok kolaudace:2020, Voda:Dálkový vodovod, Odpad:Jímka, Telekomunikace:Internet, Doprava:Silnice, Autobus, Komunikace:Dlážděná, Energetická náročnost budovy:Třída B - Velmi úsporná]  \n",
       "6                                                                                                                                    [Sklep:2m2, Voda:Dálkový vodovod, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Kabelové rozvody, Elektřina:230V, 400V, Doprava:Vlak, Silnice, MHD, Autobus, Komunikace:Asfaltová, Bezbariérový:]  \n",
       "7  [Rok rekonstrukce:2020, Voda:Dálkový vodovod, Topení:Ústřední dálkové, Odpad:Veřejná kanalizace, Telekomunikace:Telefon, Internet, Elektřina:230V, Doprava:Vlak, Dálnice, Silnice, MHD, Autobus, Komunikace:Asfaltová, Energetická náročnost budovy:Třída A - Mimořádně úsporná č. 78/2013 Sb. podle vyhlášky, Bezbariérový:, Výtah:, Typ bytu:Mezonet]  \n",
       "8                                                                                                                                                                 [Sklep:3m2, Voda:Dálkový vodovod, Topení:Jiné, Odpad:Veřejná kanalizace, Telekomunikace:Telefon, Internet, Kabelová televize, Elektřina:230V, Doprava:MHD, Komunikace:Asfaltová, Výtah:]  \n",
       "9                                                                                                                                                      [Plocha podlahová:39m2, Sklep:, Datum nastěhování:Ihned, Voda:Dálkový vodovod, Plyn:Plynovod, Energetická náročnost budovy:Třída D - Méně úsporná č. 78/2013 Sb. podle vyhlášky, Vybavení:, Výtah:]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_2_csv(rdd_df_2_pd_df(nlp_pipline_and_clean(df(rdd_l(path)))), \\\n",
    "        rdd_2_address(rdd_l(path)),\\\n",
    "        cleaned2pd_param1(register_apply_udf(rdd_l)),\\\n",
    "        cleaned2pd_param2(register_apply_udf_param2(rdd_l)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-relevance",
   "metadata": {},
   "source": [
    "#### Check in the current working directory  a file called 'cleaned_data.csv'. \n",
    "#### Finally, I was considering to clean cleanedParams1 and cleanedParams2.   \n",
    "##### But, the number of items in each row is not same, values are missing, diffently named. For Example:\n",
    "###### \"Datum nastěhování:Ihned, Rok kolaudace:2021\" is not present anywhere but row number 7. \n",
    "######  Plocha podlahová is not present in row 5 and is differenly named in some of the rest\n",
    "###### ID  is named as ID zakázky is some of the rows\n",
    "###### (420 000 EUR) is mentioned in one of the rows.\n",
    "##### Balkón:, Parkování: is present with empty values.\n",
    "#### Same with cleaParams2\n",
    "##### Keeping this in mind and also, As I ran out of time I could not do it, but its the easiest part of the entire solution.\n",
    "##### Check below the alogrithm for doing it with 5-6 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "extra-purpose",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loop over the cleanedParams1 in the UDF. \n",
    "#dict = {}\n",
    "#for i, x in enumerate(cleanedParam1.split(':')):\n",
    "#    key = i[0]\n",
    "#    value =i[1]\n",
    "#    dict[value] = key\n",
    "##### !!!!Done!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "higher-factory",
   "metadata": {},
   "source": [
    "##### Thank you for considering my application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-action",
   "metadata": {},
   "source": [
    "###### Shortcomings: Most of the data is on RDDs except Pandas dfs. I transformed RDD dfs to Pandas dfs before writing to csv. One can still directly write from RDDs using RDD joins or SQL queries on RDDs, but my time ran out so I had to do  Pandas which is quick and easy. But anyway when one calls Action task the data is dumped into the driver node instantly. My code just adds Pandas layer before dumping it to the driver node. One can even use Pandas API built on top of Spark (https://spark.apache.org/docs/latest/api/python/user_guide/pandas_on_spark/index.html). That way it will be lazy loading. That means there is a way to use pandas dfs on top of rdds and still be distributed in-memory computing.\n",
    "\n",
    "\n",
    "\n",
    "###### Another shortcoming is one can encapsulate the code in classes and call the class methods to run the entire script. I did it using functions, It's not a Production script, so I thought doing a functional way is more time-saving (I have two jobs:) and numerous other professional projects I am working on). But thanks for this task, It was a great learning. Anyways, it was just to demonstrate my skills on learning things on the fly. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-glass",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
